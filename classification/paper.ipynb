{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How Private is Android's Private DNS Setting? \n",
    "# Identifying Apps by Encrypted DNS Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random, sys, os, json, gzip, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.core.display import HTML, display\n",
    "from matplotlib import pyplot as plt, ticker\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    auc,\n",
    "    average_precision_score,\n",
    "    f1_score,\n",
    "    precision_recall_curve,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# local imports\n",
    "sys.path.append('../database/')\n",
    "import db\n",
    "from models import App, Dataset, Features, Trace\n",
    "\n",
    "# set seed for reproducibility\n",
    "myseed = 42\n",
    "np.random.seed(myseed)\n",
    "random.seed(myseed)\n",
    "\n",
    "\n",
    "# load functions\n",
    "def join_lists(tls_sizes0, times0):\n",
    "    result = []\n",
    "    for index, elems in enumerate(zip(times0, tls_sizes0)):\n",
    "        if index > 0:\n",
    "            gap = int(math.log(1 + (float(elems[0]) * 1000), 2))\n",
    "            if gap >= 5:\n",
    "                result.append(\"G\" + str(gap))\n",
    "        result.append(elems[1])\n",
    "    return result\n",
    "\n",
    "\n",
    "# load function for bursts - idea from https://github.com/spring-epfl/doh_traffic_analysis\n",
    "def create_burst_seq(x):\n",
    "    split_points = np.where(np.diff(np.sign(x)))[0] + 1\n",
    "    traffic_bursts = np.split(x, split_points)\n",
    "    burst_seq = map(sum, traffic_bursts)\n",
    "    return burst_seq\n",
    "\n",
    "\n",
    "# make a list of dataframes from database for closed world evaluation\n",
    "def get_list_of_df(world=\"closed\", cache=\"NO_CACHE\"):\n",
    "    list_of_df = []\n",
    "\n",
    "    # load DoT datasets\n",
    "    dot_resolvers = [\"dns.google\", \"dns.digitale-gesellschaft.ch\",\n",
    "                     \"dns.quad9.net\", \"one.one.one.one\", \"dot1.applied-privacy.net\"]\n",
    "    with db.session_scope() as session:\n",
    "        for resolver in dot_resolvers:\n",
    "            q = session.query(Dataset.name, Dataset.padding, Dataset.world, Dataset.caching, Trace.timestamp, \n",
    "                              Features).join(Features).join(App).join(Dataset).filter(\n",
    "                Dataset.hostname == resolver, Dataset.dns_type == \"dot\", Dataset.caching == cache, \n",
    "                Dataset.world == world).order_by(Features.id)\n",
    "            sql_df = pd.read_sql(q.statement, q.session.bind)\n",
    "            sql_df = shuffle(sql_df, random_state=myseed)\n",
    "            list_of_df.append(sql_df)\n",
    "\n",
    "    # load DoH datasets\n",
    "    doh_resolvers = [\"dns.google\", \"dns.digitale-gesellschaft.ch\",\n",
    "                     \"dns.quad9.net\", \"cloudflare-dns.com\", \"doh.applied-privacy.net\"]\n",
    "\n",
    "    with db.session_scope() as session:\n",
    "        for resolver in doh_resolvers:\n",
    "            q = session.query(Dataset.name, Dataset.padding, Dataset.world, Dataset.caching, Trace.timestamp, \n",
    "                              Features).join(Features).join(App).join(Dataset).filter(\n",
    "                Dataset.hostname == resolver, Dataset.dns_type == \"doh\", Dataset.caching == cache, \n",
    "                Dataset.world == world).order_by(Features.id)\n",
    "            sql_df = pd.read_sql(q.statement, q.session.bind)\n",
    "            sql_df = shuffle(sql_df, random_state=myseed)\n",
    "            list_of_df.append(sql_df)\n",
    "    return list_of_df\n",
    "\n",
    "\n",
    "# make a list of dataframes from database for closed world evaluation\n",
    "def get_list_of_df_weeks():\n",
    "    list_of_df = []\n",
    "    dates_db = [('2020-04-25 13:00:00', '2020-05-02 13:00:00'), ('2020-05-02 13:01:00', '2020-05-09 13:00:00'),\n",
    "                ('2020-05-09 13:01:00', '2020-05-16 13:00:00'), ('2020-05-16 13:01:00', '2020-05-20 13:00:00')]\n",
    "    for mydate in dates_db:\n",
    "        lower_date = mydate[0]\n",
    "        upper_date = mydate[1]\n",
    "        # load DoT datasets\n",
    "        dot_resolvers = [\"dns.google\", \"dns.digitale-gesellschaft.ch\",\n",
    "                         \"dns.quad9.net\", \"one.one.one.one\", \"dot1.applied-privacy.net\"]\n",
    "        with db.session_scope() as session:\n",
    "            for resolver in dot_resolvers:\n",
    "                q = session.query(Dataset.name, Dataset.padding, Dataset.world, Dataset.caching, \n",
    "                                  Trace.timestamp, Features).join(Features).join(App).join(Dataset).filter(\n",
    "                    Dataset.hostname == resolver, Dataset.dns_type == \"dot\", Dataset.caching == \"NO_CACHE\",\n",
    "                    Dataset.world == \"closed\", Features.datetime_trace <= upper_date,\n",
    "                    Features.datetime_trace > lower_date).order_by(Features.id)\n",
    "                sql_df = pd.read_sql(q.statement, q.session.bind)\n",
    "                sql_df = shuffle(sql_df, random_state=myseed)\n",
    "                list_of_df.append(sql_df)\n",
    "\n",
    "        # load DoH datasets\n",
    "        doh_resolvers = [\"dns.google\", \"dns.digitale-gesellschaft.ch\",\n",
    "                         \"dns.quad9.net\", \"cloudflare-dns.com\", \"doh.applied-privacy.net\"]\n",
    "\n",
    "        with db.session_scope() as session:\n",
    "            for resolver in doh_resolvers:\n",
    "                q = session.query(Dataset.name, Dataset.padding, Dataset.world, Dataset.caching,\n",
    "                                  Trace.timestamp, Features).join(Features).join(App).join(Dataset).filter(\n",
    "                    Dataset.hostname == resolver, Dataset.dns_type == \"doh\", Dataset.caching == \"NO_CACHE\",\n",
    "                    Dataset.world == \"closed\", Features.datetime_trace <= upper_date, \n",
    "                    Features.datetime_trace > lower_date).order_by(Features.id)\n",
    "                sql_df = pd.read_sql(q.statement, q.session.bind)\n",
    "                sql_df = shuffle(sql_df, random_state=myseed)\n",
    "                list_of_df.append(sql_df)\n",
    "    return list_of_df\n",
    "\n",
    "\n",
    "def create_tls_fd_df(prep_df):\n",
    "    predict_df = pd.DataFrame()\n",
    "    predict_df['app_name'] = prep_df.app_name\n",
    "    predict_df['tls_sizes'] = prep_df.tls_sizes\n",
    "    predict_df['tls_sizes'] = [' '.join(map(str, tls_len)) for tls_len in predict_df['tls_sizes']]\n",
    "    return predict_df\n",
    "\n",
    "\n",
    "def create_n_grams_df(prep_df):\n",
    "    predict_df = pd.DataFrame()\n",
    "    predict_df['app_name'] = prep_df.app_name\n",
    "    predict_df['n-grams'] = prep_df.tls_sizes.map(lambda x: create_burst_seq(np.array([int(elem) for elem in x])))\n",
    "    predict_df['n-grams'] = [' '.join(map(str, ng)) for ng in predict_df['n-grams']]\n",
    "    predict_df['tls_sizes'] = [' '.join(map(str, tl))for tl in prep_df['tls_sizes']]\n",
    "    return predict_df\n",
    "\n",
    "\n",
    "def create_dns_sequences(prep_df):\n",
    "    predict_df = pd.DataFrame()\n",
    "    predict_df['app_name'] = prep_df['app_name']\n",
    "    predict_df['tls_sizes'] = prep_df.tls_sizes\n",
    "    predict_df['times'] = prep_df.tls_sizes_times\n",
    "    predict_df['dns_seq'] = predict_df.apply(lambda x: join_lists(x.tls_sizes, x.times), axis=1)\n",
    "    predict_df['dns_seq'] = [' '.join(map(str, seq)) for seq in predict_df['dns_seq']]\n",
    "    return predict_df\n",
    "\n",
    "\n",
    "def build_ow_dataframe(total_df, class_problem, rand_seed, app_list, number_monitored_sites, n_monitored,\n",
    "                       test_size_mon, num_unm, n_unknown_train, n_unknown_test, sample_unm,test_unm, \n",
    "                       sample_unknown):\n",
    "    np.random.seed(rand_seed)\n",
    "    # select n monitored sites from open world with m instances\n",
    "    interested = np.random.choice(app_list, number_monitored_sites, replace=False)\n",
    "    monitored_df = total_df.loc[total_df['app_name'].isin(interested)].copy()\n",
    "    monitored_df = monitored_df.groupby('app_name', group_keys=False).apply(\n",
    "        lambda x: x.sample(n=n_monitored, random_state=myseed))\n",
    "    if class_problem == \"binary\":\n",
    "        monitored_df['target'] = \"monitored\"\n",
    "    else:\n",
    "        monitored_df['target'] = monitored_df.app_name\n",
    "    # use x instances of monitored sites for training and y instances for testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(monitored_df, monitored_df.world, \n",
    "                                                        test_size=test_size_mon, random_state=myseed, \n",
    "                                                        stratify=monitored_df.app_name)\n",
    "\n",
    "    # select rest of apps and tag them as unmonitored\n",
    "    unmonitored_df = total_df.loc[total_df['app_name'].isin(interested) == False].copy()\n",
    "    unmonitored_df['target'] = \"unmonitored\"\n",
    "\n",
    "    # use i unmonitored apps for training and j as unknown in testing\n",
    "    np.random.seed(rand_seed)\n",
    "    unmonitored_apps_list = np.unique(unmonitored_df.app_name)\n",
    "    interested_unmonitored = np.random.choice(unmonitored_apps_list, num_unm, replace=False)\n",
    "    unknown_train = interested_unmonitored[:n_unknown_train]\n",
    "    unknown_test = interested_unmonitored[n_unknown_test:]\n",
    "\n",
    "    # take k instance of unmonitored apps for training\n",
    "    unmonitored_df_train = unmonitored_df.loc[unmonitored_df['app_name'].isin(unknown_train)]\n",
    "    unmonitored_df_train = unmonitored_df_train.groupby('app_name',group_keys=False).apply(\n",
    "        lambda x:x.sample(n=sample_unm, random_state=myseed))\n",
    "    X_train_unm, X_test_unm, y_train_unm, y_test_unm = train_test_split(unmonitored_df_train,\n",
    "                                                                        unmonitored_df_train.world,\n",
    "                                                                        test_size=test_unm,\n",
    "                                                                        random_state=myseed,\n",
    "                                                                    stratify=unmonitored_df_train.app_name)\n",
    "    # take l instances for each of the j unknown apps\n",
    "    unmonitored_df_test = unmonitored_df.loc[unmonitored_df['app_name'].isin(unknown_test)]\n",
    "    unmonitored_df_test = unmonitored_df_test.groupby('app_name', group_keys=False).apply(\n",
    "        lambda x: x.sample(n=sample_unknown, random_state=myseed))\n",
    "\n",
    "    # final datasets\n",
    "    training_data = X_train.append(X_train_unm, ignore_index=True).copy()\n",
    "    training_data = shuffle(training_data, random_state=myseed)\n",
    "    test_data = X_test.append(unmonitored_df_test, ignore_index=True).copy()\n",
    "    test_data = shuffle(test_data, random_state=myseed)\n",
    "    return training_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Approach based on TLS Record Size Frequency Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tls_fd(dataframes):\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1scores = []\n",
    "    for df in dataframes:\n",
    "        resolver_metrics = []\n",
    "        print(f\"TLS Record Sizes - {df.name.value_counts().index[0]}\")\n",
    "        print(\"Shape of Dataframe: \" + str(df.shape))\n",
    "        print(\"Minimum Traces per App:\", np.min(df['app_name'].value_counts()))\n",
    "        predict_df = create_tls_fd_df(df)\n",
    "        vectorizer = TfidfVectorizer(tokenizer=lambda x: x.split(\" \"), use_idf=False, sublinear_tf=False,\n",
    "                                     norm='', smooth_idf=False)\n",
    "\n",
    "        X = vectorizer.fit_transform(predict_df['tls_sizes'])\n",
    "        y = predict_df[\"app_name\"]\n",
    "\n",
    "        # random forest model creation\n",
    "        rfc = RandomForestClassifier(n_jobs=-1, random_state=myseed)\n",
    "        mnb = MultinomialNB()\n",
    "        knn = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "        svc = SVC(random_state=myseed)\n",
    "        mlp = MLPClassifier(random_state=myseed)\n",
    "        scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    "        skf = StratifiedKFold(n_splits=5, random_state=myseed, shuffle=True)\n",
    "        with warnings.catch_warnings():\n",
    "            print(\"after: \" + str(X.shape))\n",
    "            warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "            rfc_cv_score = cross_validate(rfc, X, y, cv=skf, scoring=scoring)\n",
    "        print(\"Accuracy: %0.3f (+/- %0.3f)\" % (rfc_cv_score['test_accuracy'].mean(),\n",
    "                                               rfc_cv_score['test_accuracy'].std()))\n",
    "        print(\"Precision: %0.3f (+/- %0.3f)\" % (rfc_cv_score['test_precision_macro'].mean(), \n",
    "                                                rfc_cv_score['test_precision_macro'].std()))\n",
    "        print(\"Recall: %0.3f (+/- %0.3f)\" % (rfc_cv_score['test_recall_macro'].mean(),\n",
    "                                             rfc_cv_score['test_recall_macro'].std()))\n",
    "        print(\"F1-Score: %0.3f (+/- %0.3f)\" % (rfc_cv_score['test_f1_macro'].mean(), \n",
    "                                               rfc_cv_score['test_f1_macro'].std()))\n",
    "        resolver_metrics.extend([\"%0.3f\" % rfc_cv_score['test_accuracy'].mean(), \n",
    "                                 \"%0.3f\" % rfc_cv_score['test_precision_macro'].mean(),\n",
    "                                 \"%0.3f\" % rfc_cv_score['test_recall_macro'].mean(), \n",
    "                                 \"%0.3f\" % rfc_cv_score['test_f1_macro'].mean()])\n",
    "        print(df.name.value_counts().index[0], str(resolver_metrics).replace(\"'\", \"\"))\n",
    "        print(\"\\n\")\n",
    "        accuracies.append(\"%0.3f\" % rfc_cv_score['test_accuracy'].mean())\n",
    "        precisions.append(\"%0.3f\" % rfc_cv_score['test_precision_macro'].mean())\n",
    "        recalls.append(\"%0.3f\" % rfc_cv_score['test_recall_macro'].mean())\n",
    "        f1scores.append(\"%0.3f\" % rfc_cv_score['test_f1_macro'].mean())\n",
    "    print(\"Accuracies:\", str(accuracies).replace(\"'\", \"\"))\n",
    "    print(\"Precisions:\", str(precisions).replace(\"'\", \"\"))\n",
    "    print(\"Recalls:\", str(recalls).replace(\"'\", \"\"))\n",
    "    print(\"F1 scores:\", str(f1scores).replace(\"'\", \"\"))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# prediction on raw dataset for each recursive resolver\n",
    "list_of_df = get_list_of_df()\n",
    "predict_tls_fd(list_of_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Approach based on N-Grams of TLS Record Sizes / Bursts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE BURSTS, N-GRAMS AND TLS SIZES\n",
    "def predict_ngrams_tls_sizes(dataframes):\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1scores = []\n",
    "    for df in dataframes:\n",
    "        resolver_metrics = []\n",
    "        print(f\"N-Grams - {df.name.value_counts().index[0]}\")\n",
    "        print(\"Shape of Dataframe: \" + str(df.shape))\n",
    "        print(\"Minimum Traces per App:\", np.min(df['app_name'].value_counts()))\n",
    "        # create dataframe for prediction\n",
    "        predict_df = create_n_grams_df(df)\n",
    "        # vectorizer\n",
    "        vectorizer = TfidfVectorizer(tokenizer=lambda x: x.split(\" \"), ngram_range=(1, 2), use_idf=False,\n",
    "                                     sublinear_tf=False, norm='', smooth_idf=False)\n",
    "        vectorizer2 = TfidfVectorizer(tokenizer=lambda x: x.split(\" \"), ngram_range=(1, 2), use_idf=False,\n",
    "                                      sublinear_tf=False, norm='', smooth_idf=False)\n",
    "        # feature for n-grams\n",
    "        X0 = vectorizer.fit_transform(predict_df['n-grams'])\n",
    "        # features based on tls sizes\n",
    "        X1 = vectorizer.fit_transform(predict_df.tls_sizes)\n",
    "        # combine features\n",
    "        X = hstack([X0, X1])\n",
    "        y = predict_df[\"app_name\"]\n",
    "\n",
    "        # random forest model creation\n",
    "        scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    "        rfc = RandomForestClassifier(n_jobs=-1, random_state=myseed)\n",
    "        MultinomialNB()\n",
    "        knn = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "        skf = StratifiedKFold(n_splits=5, random_state=myseed, shuffle=True)\n",
    "        with warnings.catch_warnings():\n",
    "            print(\"after: \" + str(X.shape))\n",
    "            warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "            rfc_cv_score = cross_validate(rfc, X, y, cv=skf, scoring=scoring)\n",
    "        print(\"Accuracy: %0.3f (+/- %0.3f)\" % (rfc_cv_score['test_accuracy'].mean(), \n",
    "                                               rfc_cv_score['test_accuracy'].std()))\n",
    "        print(\"Precision: %0.3f (+/- %0.3f)\" % (rfc_cv_score['test_precision_macro'].mean(), \n",
    "                                                rfc_cv_score['test_precision_macro'].std()))\n",
    "        print(\"Recall: %0.3f (+/- %0.3f)\" % (rfc_cv_score['test_recall_macro'].mean(), \n",
    "                                             rfc_cv_score['test_recall_macro'].std()))\n",
    "        print(\"F1-Score: %0.3f (+/- %0.3f)\" % (rfc_cv_score['test_f1_macro'].mean(), \n",
    "                                               rfc_cv_score['test_f1_macro'].std()))\n",
    "        resolver_metrics.extend([\"%0.3f\" % rfc_cv_score['test_accuracy'].mean(), \n",
    "                                 \"%0.3f\" % rfc_cv_score['test_precision_macro'].mean(),\n",
    "                                 \"%0.3f\" % rfc_cv_score['test_recall_macro'].mean(), \n",
    "                                 \"%0.3f\" % rfc_cv_score['test_f1_macro'].mean()])\n",
    "        print(df.name.value_counts().index[0], str(resolver_metrics).replace(\"'\", \"\"))\n",
    "        print(\"\\n\")\n",
    "        accuracies.append(\"%0.3f\" % rfc_cv_score['test_accuracy'].mean())\n",
    "        precisions.append(\"%0.3f\" % rfc_cv_score['test_precision_macro'].mean())\n",
    "        recalls.append(\"%0.3f\" % rfc_cv_score['test_recall_macro'].mean())\n",
    "        f1scores.append(\"%0.3f\" % rfc_cv_score['test_f1_macro'].mean())\n",
    "    print(\"Accuracies:\", str(accuracies).replace(\"'\", \"\"))\n",
    "    print(\"Precisions:\", str(precisions).replace(\"'\", \"\"))\n",
    "    print(\"Recalls:\", str(recalls).replace(\"'\", \"\"))\n",
    "    print(\"F1 scores:\", str(f1scores).replace(\"'\", \"\"))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# prediction on raw dataset for each recursive resolver\n",
    "list_of_df = get_list_of_df()\n",
    "predict_ngrams_tls_sizes(list_of_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Approach Distances of DNS Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./distances_resp/\"\n",
    "gzip_files = os.listdir(path)\n",
    "gzip_files = [gfile for gfile in gzip_files if gfile.endswith(\"gz\")]\n",
    "\n",
    "for gzip_file in gzip_files:\n",
    "    path_df = f\"./pickle_resp/{gzip_file.split('.json')[0]}\"\n",
    "    predict_df = pd.read_pickle(path_df)    \n",
    "    with gzip.open(path + gzip_file) as f:\n",
    "        results = json.load(f)\n",
    "        distances = results['results']\n",
    "        dimension = max(distance['i'] for distance in distances) + 1\n",
    "        matrix = np.zeros(dimension**2, dtype=int).reshape((dimension, dimension))\n",
    "        for distance in distances:\n",
    "            i = distance['i']\n",
    "            j = distance['j']\n",
    "            d = distance['distance']\n",
    "            matrix[i,j] = matrix[j,i] = d\n",
    "\n",
    "    print(f\"\\nBushart et al. - {gzip_file}\")\n",
    "\n",
    "    # feature w. timing\n",
    "    X = matrix\n",
    "    y = predict_df[\"app_name\"]\n",
    "\n",
    "    # knn classifier\n",
    "    scoring = ['accuracy']\n",
    "    knn = KNeighborsClassifier(n_neighbors=1, n_jobs=-1, metric=\"precomputed\")\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=myseed, shuffle=True)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "        rfc_cv_score = cross_validate(knn, X, y, cv=skf, scoring=scoring)\n",
    "    print(\"Accuracy: %0.3f (+/- %0.3f)\" % (rfc_cv_score['test_accuracy'].mean(), \n",
    "                                           rfc_cv_score['test_accuracy'].std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Segram: N-Grams of DNS Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix, hstack\n",
    "\n",
    "def predict_ngrams_dns_seq(dflist, target='app_name'):\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1scores = []\n",
    "    for df in dflist:\n",
    "        resolver_metrics = []\n",
    "        print(f\"N-Grams / Times - {df.name.value_counts().index[0]}\")\n",
    "        print(\"Shape of Dataframe: \" + str(df.shape))\n",
    "        print(\"Minimum Traces per App:\", np.min(df['app_name'].value_counts()))\n",
    "        # create dataframe for prediction\n",
    "        predict_df = create_dns_sequences(df)\n",
    "        # vectorizer and transformer\n",
    "        vectorizer = TfidfVectorizer(tokenizer=lambda x: x.split(\" \"), ngram_range=(1, 3), use_idf=False,\n",
    "                                     sublinear_tf=False, norm='', smooth_idf=False)\n",
    "        # feature w. timing\n",
    "        X = vectorizer.fit_transform(predict_df['dns_seq'])\n",
    "        y = predict_df[target]\n",
    "\n",
    "        # random forest model creation\n",
    "        scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    "        rfc = RandomForestClassifier(n_jobs=-1, random_state=myseed)\n",
    "        MultinomialNB()\n",
    "        knn = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "        skf = StratifiedKFold(n_splits=5, random_state=myseed, shuffle=True)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "            rfc_cv_score = cross_validate(rfc, X, y, cv=skf, scoring=scoring)\n",
    "\n",
    "        print(\"Accuracy: %0.3f (+/- %0.3f)\" % (rfc_cv_score['test_accuracy'].mean(), \n",
    "                                               rfc_cv_score['test_accuracy'].std()))\n",
    "        print(\"Precision: %0.3f (+/- %0.3f)\" % (rfc_cv_score['test_precision_macro'].mean(), \n",
    "                                                rfc_cv_score['test_precision_macro'].std()))\n",
    "        print(\"Recall: %0.3f (+/- %0.3f)\" % (rfc_cv_score['test_recall_macro'].mean(),\n",
    "                                             rfc_cv_score['test_recall_macro'].std()))\n",
    "        print(\"F1-Score: %0.3f (+/- %0.3f)\" % (rfc_cv_score['test_f1_macro'].mean(),\n",
    "                                               rfc_cv_score['test_f1_macro'].std()))\n",
    "        resolver_metrics.extend([\"%0.3f\" % rfc_cv_score['test_accuracy'].mean(), \n",
    "                                 \"%0.3f\" % rfc_cv_score['test_precision_macro'].mean(),\n",
    "                                 \"%0.3f\" % rfc_cv_score['test_recall_macro'].mean(), \n",
    "                                 \"%0.3f\" % rfc_cv_score['test_f1_macro'].mean()])\n",
    "        print(df.name.value_counts().index[0], str(resolver_metrics).replace(\"'\", \"\"))\n",
    "        print(\"\\n\")\n",
    "        accuracies.append(\"%0.3f\" % rfc_cv_score['test_accuracy'].mean())\n",
    "        precisions.append(\"%0.3f\" % rfc_cv_score['test_precision_macro'].mean())\n",
    "        recalls.append(\"%0.3f\" % rfc_cv_score['test_recall_macro'].mean())\n",
    "        f1scores.append(\"%0.3f\" % rfc_cv_score['test_f1_macro'].mean())\n",
    "    print(\"Accuracies:\", str(accuracies).replace(\"'\", \"\"))\n",
    "    print(\"Precisions:\", str(precisions).replace(\"'\", \"\"))\n",
    "    print(\"Recalls:\", str(recalls).replace(\"'\", \"\"))\n",
    "    print(\"F1 scores:\", str(f1scores).replace(\"'\", \"\"))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# prediction on raw dataset for each recursive resolver\n",
    "list_of_df = get_list_of_df()\n",
    "predict_ngrams_dns_seq(list_of_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Influence of Sample Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get traces for resolvers from first week\n",
    "week_dfs = get_list_of_df_weeks()\n",
    "resolver_week1 = [week_dfs[0], week_dfs[4], week_dfs[5], week_dfs[9]]\n",
    "sample_sizes = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
    "\n",
    "for res in resolver_week1:\n",
    "    accs = []\n",
    "    print(res.name.value_counts().index[0])\n",
    "    for sample_size in sample_sizes:\n",
    "        mydf = res.groupby('app_name', group_keys=False).apply(lambda x: x.sample(n=sample_size,\n",
    "                                                                                  random_state=myseed))\n",
    "        mydf = shuffle(mydf, random_state=myseed)\n",
    "        X_test_df = res.drop(mydf.index)\n",
    "        predict_df = create_dns_sequences(mydf)\n",
    "        \n",
    "        # vectorizer and transformer\n",
    "        vectorizer = TfidfVectorizer(tokenizer=lambda x: x.split(\" \"), ngram_range=(1, 3), use_idf=False,\n",
    "                                     sublinear_tf=False, norm='', smooth_idf=False)\n",
    "\n",
    "        X = vectorizer.fit_transform(predict_df['dns_seq'])\n",
    "        y = predict_df['app_name']\n",
    "        rfc = RandomForestClassifier(n_jobs=-1, random_state=myseed)\n",
    "        rfc.fit(X, y)\n",
    "        \n",
    "        # classify test data\n",
    "        predict_df_test = create_dns_sequences(X_test_df)\n",
    "        X_test = vectorizer.transform(predict_df_test['dns_seq'])\n",
    "        y_test = predict_df_test['app_name']\n",
    "        y_pred = rfc.predict(X_test)\n",
    "        print(\"Instances: \", sample_size, \"Accuracy\", \"%0.3f\" % accuracy_score(y_test, y_pred))\n",
    "        accs.append(\"%0.3f\" % accuracy_score(y_test, y_pred))\n",
    "    #print(accs)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Influence of Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "week_dfs = get_list_of_df_weeks()\n",
    "resolver_week1 = week_dfs[:10]\n",
    "resolver_week2 = week_dfs[10:20]\n",
    "resolver_week3 = week_dfs[20:30]\n",
    "resolver_week4 = week_dfs[30:40]\n",
    "resolver_indices = [0, 4, 5, 9]\n",
    "\n",
    "for resolver_index in resolver_indices:\n",
    "    mydfs = [resolver_week1[resolver_index], resolver_week2[resolver_index],\n",
    "             resolver_week3[resolver_index], resolver_week4[resolver_index]]\n",
    "\n",
    "    for i in range(1):\n",
    "        print(\"Position\", i+1, i+1)\n",
    "        df = mydfs[i]\n",
    "        print(f\"Resolver - {df.name.value_counts().index[0]}\")\n",
    "        # base\n",
    "        predict_ngrams_dns_seq([df])\n",
    "        for j in range(4):\n",
    "            if i != j:\n",
    "                # create model\n",
    "                predict_df = create_dns_sequences(df)\n",
    "                # vectorizer and transformer\n",
    "                vectorizer = TfidfVectorizer(tokenizer=lambda x: x.split(\" \"), ngram_range=(1, 3), \n",
    "                                             use_idf=False, sublinear_tf=False, norm='', smooth_idf=False)\n",
    "\n",
    "                X = vectorizer.fit_transform(predict_df['dns_seq'])\n",
    "                y = predict_df['app_name']\n",
    "                rfc = RandomForestClassifier(n_jobs=-1, random_state=myseed)\n",
    "                rfc.fit(X, y)\n",
    "\n",
    "                new_data = mydfs[j]\n",
    "                predict_df = create_dns_sequences(new_data)\n",
    "                X_test = vectorizer.transform(predict_df['dns_seq'])\n",
    "                y_test = predict_df['app_name']\n",
    "\n",
    "                y_pred = rfc.predict(X_test)\n",
    "                print(\"Position\", j+1, i+1)\n",
    "                print(\"Accuracy\", \"%0.3f\" % accuracy_score(y_test, y_pred))\n",
    "                print(\"\\n\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train + Predict with Different Resolver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 DoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mydfs = get_list_of_df(world=\"closed\", cache=\"NO_CACHE\")[:5]\n",
    "for i in range(len(mydfs)):\n",
    "    print(\"Position\", i+1, i+1)\n",
    "    df = mydfs[i]\n",
    "    print(f\"Resolver - {df.name.value_counts().index[0]}\")\n",
    "    # base\n",
    "    predict_ngrams_dns_seq([df])\n",
    "    for j in range(len(mydfs)):\n",
    "        if i != j:\n",
    "            # create model\n",
    "            predict_df = create_dns_sequences(df)\n",
    "            # vectorizer and transformer\n",
    "            vectorizer = TfidfVectorizer(tokenizer=lambda x: x.split(\" \"), ngram_range=(1, 3),\n",
    "                                         use_idf=False, sublinear_tf=False, norm='', smooth_idf=False)\n",
    "\n",
    "            X = vectorizer.fit_transform(predict_df['dns_seq'])\n",
    "            y = predict_df['app_name']\n",
    "            rfc = RandomForestClassifier(n_jobs=-1, random_state=myseed)\n",
    "            rfc.fit(X, y)\n",
    "\n",
    "            new_data = mydfs[j]\n",
    "            print(f\"Resolver - {new_data.name.value_counts().index[0]}\")\n",
    "            predict_df_new = create_dns_sequences(new_data)\n",
    "            X_test = vectorizer.transform(predict_df_new['dns_seq'])\n",
    "            y_test = predict_df_new['app_name']\n",
    "\n",
    "            y_pred = rfc.predict(X_test)\n",
    "            print(\"Position\", j+1, i+1)\n",
    "            print(\"Accuracy\", \"%0.3f\" % accuracy_score(y_test, y_pred))\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 DoH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mydfs = get_list_of_df(world=\"closed\", cache=\"NO_CACHE\")[5:]\n",
    "for i in range(len(mydfs)):\n",
    "    print(\"Position\", i+1, i+1)\n",
    "    df = mydfs[i]\n",
    "    print(f\"Resolver - {df.name.value_counts().index[0]}\")\n",
    "    # base\n",
    "    predict_ngrams_dns_seq([df])\n",
    "    for j in range(len(mydfs)):\n",
    "        if i != j:\n",
    "            # create model\n",
    "            predict_df = create_dns_sequences(df)\n",
    "            # vectorizer and transformer\n",
    "            vectorizer = TfidfVectorizer(tokenizer=lambda x: x.split(\" \"), ngram_range=(1, 3), \n",
    "                                         use_idf=False, sublinear_tf=False, norm='', smooth_idf=False)\n",
    "\n",
    "            X = vectorizer.fit_transform(predict_df['dns_seq'])\n",
    "            y = predict_df['app_name']\n",
    "            rfc = RandomForestClassifier(n_jobs=-1, random_state=myseed)\n",
    "            rfc.fit(X, y)\n",
    "\n",
    "            new_data = mydfs[j]\n",
    "            print(f\"Resolver - {new_data.name.value_counts().index[0]}\")\n",
    "            predict_df_new = create_dns_sequences(new_data)\n",
    "            X_test = vectorizer.transform(predict_df_new['dns_seq'])\n",
    "            y_test = predict_df_new['app_name']\n",
    "\n",
    "            y_pred = rfc.predict(X_test)\n",
    "            print(\"Position\", j+1, i+1)\n",
    "            print(\"Accuracy\", \"%0.3f\" % accuracy_score(y_test, y_pred))\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Impact of Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list_of_df_cache = get_list_of_df(cache=\"CACHE\")\n",
    "predict_ngrams_dns_seq(list_of_df_cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Open World"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 Binary-Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "random.seed(myseed)\n",
    "resolver_indices = {0:\"Google DoT\", 4:\"Applied Privacy DoT\", 5:\"Google DoH\", 9:\"Applied Privacy DoH\"}\n",
    "for resolver_index, resolver_text in resolver_indices.items():\n",
    "    number_monitored_sites = 10\n",
    "\n",
    "    cw_data = get_list_of_df()[resolver_index]\n",
    "    ow_data = get_list_of_df(world=\"open\")[resolver_index]\n",
    "\n",
    "    total_df = cw_data.append(ow_data, ignore_index=True)\n",
    "    app_list = np.unique(cw_data.app_name)\n",
    "    seeds = [42, 24, 2, 4]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    f_scores = np.linspace(0.0, 0.8, num=5)\n",
    "    lines = []\n",
    "    labels = []\n",
    "    for i, f_score in enumerate(f_scores):\n",
    "        xf = np.linspace(0.01, 1)\n",
    "        yf = f_score * xf / (2 * xf - f_score)\n",
    "        l, = plt.plot(xf[yf >= 0], yf[yf >= 0], color='gray', alpha=0.2)\n",
    "        if i > 0:\n",
    "            plt.annotate(' F1={0:0.1f}'.format(f_score),xy=(0.85, yf[45] + 0.035), fontsize=16)\n",
    "    y_real = []\n",
    "    y_proba = []\n",
    "    print(f\"Resolver - {total_df.name.value_counts().index[0]}\")\n",
    "    for s in seeds:\n",
    "        training_data, test_data = build_ow_dataframe(total_df, \"binary\", s, app_list, number_monitored_sites,\n",
    "                                                      40, 0.25, 200, 100, 100, 10, 7/10, 12)\n",
    "        predict_df_train = create_dns_sequences(training_data)\n",
    "        predict_df_test = create_dns_sequences(test_data)\n",
    "\n",
    "        # vectorizer and transformer\n",
    "        vectorizer = TfidfVectorizer(tokenizer=lambda x: x.split(\" \"), ngram_range=(1, 3),\n",
    "                                     use_idf=False, sublinear_tf=False, norm='', smooth_idf=False)\n",
    "\n",
    "        X = vectorizer.fit_transform(predict_df_train['dns_seq'])\n",
    "        y = training_data[\"target\"]\n",
    "        rfc = RandomForestClassifier(n_jobs=-1, random_state=myseed)\n",
    "        rfc.fit(X, y)\n",
    "        newdf = vectorizer.transform(predict_df_test['dns_seq'])\n",
    "        scores = rfc.predict_proba(newdf)\n",
    "        precision, recall, thresholds = precision_recall_curve(test_data['target'], scores[:, 0], pos_label=rfc.classes_[0])\n",
    "        y_pred = rfc.predict(newdf)\n",
    "        # plot precision-recall curve\n",
    "        #ax.plot(recall, precision, marker='.', label=None, alpha=0.2, color=\"lightgray\")\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        y_real.append(test_data['target'])\n",
    "        y_proba.append(scores[:, 0])\n",
    "\n",
    "    # plot the no skill precision-recall curve\n",
    "    y_real = np.concatenate(y_real)\n",
    "    y_proba = np.concatenate(y_proba)\n",
    "    precision, recall, thresholds = precision_recall_curve(y_real, y_proba, pos_label='monitored')\n",
    "    lab = 'Random Forest' % (average_precision_score(y_real, y_proba, pos_label='monitored'))\n",
    "    \n",
    "    ax.plot(recall, precision, label=lab, lw=2, color='black')\n",
    "    ax.set_xlabel('Recall', fontsize=20, labelpad=8)\n",
    "    ax.set_ylabel('Precision', fontsize=20, labelpad=8)\n",
    "\n",
    "    positions = [0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "    labels = [None, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "    ax.yaxis.set_major_locator(ticker.FixedLocator(positions))\n",
    "    ax.yaxis.set_major_formatter(ticker.FixedFormatter(labels))\n",
    "\n",
    "    ax.tick_params(labelsize=20)\n",
    "\n",
    "    # calculate the no skill line as the proportion of the positive class\n",
    "    no_skill = len(test_data['target'][test_data['target'] == 'monitored']) / len(test_data['target'])\n",
    "    print(\"NoSkill: \" + str(no_skill))\n",
    "    ax.plot([0, 1], [no_skill, no_skill], linestyle='--',label='Random Classifier', color=\"darkgrey\")\n",
    "\n",
    "    ax.legend(bbox_to_anchor=(0, 0.985, 1, 0.15), loc=\"lower left\", mode=\"expand\", borderaxespad=0, \n",
    "              ncol=3, fontsize=18, frameon=False)\n",
    "    f1_scores = 2*recall*precision/(recall+precision)\n",
    "    index_f1 = np.argmax(f1_scores)    \n",
    "    best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "    print('Best threshold: ', best_threshold)\n",
    "    print('Best F1-Score: ', np.max(f1_scores))\n",
    "    print(\"Best Precision:\", precision[np.argmax(f1_scores)])\n",
    "    print(\"Best Recall:\", recall[np.argmax(f1_scores)])\n",
    "\n",
    "    try:\n",
    "        if resolver_index==0:\n",
    "            os.remove(\"ow_results.csv\")\n",
    "    except OSError:\n",
    "        pass\n",
    "    with open('ow_results.csv','a') as file:\n",
    "        #file.write(\"resolver,precision,recall,best_threshold,best_precision,best_recall\\n\")\n",
    "        file.write(resolver_text + \"\\t\")\n",
    "        file.write(\"%s\\t\" % list(precision))\n",
    "        file.write(\"%s\\t\" % list(recall))\n",
    "        file.write(\"%s\\t\" % best_threshold)\n",
    "        file.write(\"%s\\t\" % precision[index_f1])\n",
    "        file.write(\"%s\" % recall[index_f1])\n",
    "        file.write('\\n')\n",
    "        \n",
    "    ax.plot([recall[np.where(thresholds == best_threshold)]], [precision[np.where(thresholds == best_threshold)]],\n",
    "            marker='o', markersize=8, color=\"black\")\n",
    "    ax.annotate(f\"t={'%.2f' % thresholds[np.argmax(f1_scores)]}\",\n",
    "                xy=(recall[np.where(thresholds == best_threshold)]-0.07, \n",
    "                    precision[np.where(thresholds == best_threshold)]+0.055),\n",
    "                textcoords='data', fontsize=16)\n",
    "    ax.text(0.5, 0.7, resolver_text, fontsize=20, horizontalalignment='center', alpha=1)\n",
    "    #save_path = f\"prcurve_{resolver_text}\"\n",
    "    #plt.savefig(save_path + \".pdf\", bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2 Multi-Class Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "myseed = 42\n",
    "random.seed(myseed)\n",
    "\n",
    "resolver_indices = np.arange(0, 10)\n",
    "for i in resolver_indices:\n",
    "    resolver_index = i\n",
    "    number_monitored_sites = 10\n",
    "\n",
    "    cw_data = get_list_of_df()[resolver_index]\n",
    "    ow_data = get_list_of_df(world=\"open\")[resolver_index]\n",
    "\n",
    "    total_df = cw_data.append(ow_data, ignore_index=True)\n",
    "    app_list = np.unique(cw_data.app_name)\n",
    "    seeds = [42, 24, 2, 4]\n",
    "    print(f\"Resolver - {total_df.name.value_counts().index[0]}\")\n",
    "    all_f1 = []\n",
    "    all_prec = []\n",
    "    all_rec = []\n",
    "    for s in seeds:\n",
    "        training_data, test_data = build_ow_dataframe(\n",
    "            total_df, \"multi-class\", s, app_list, \n",
    "            number_monitored_sites, 40, 0.25, 200, 100, 100, 10, 7/10, 12)\n",
    "        predict_df_train = create_dns_sequences(training_data)\n",
    "        predict_df_test = create_dns_sequences(test_data)\n",
    "        # vectorizer and transformer\n",
    "        vectorizer = TfidfVectorizer(tokenizer=lambda x: x.split(\" \"), ngram_range=(1, 3), use_idf=False,\n",
    "                                     sublinear_tf=False, norm='', smooth_idf=False)\n",
    "\n",
    "        X = vectorizer.fit_transform(predict_df_train['dns_seq'])\n",
    "        y = training_data[\"target\"]\n",
    "        rfc = RandomForestClassifier(n_jobs=-1, random_state=myseed)\n",
    "        rfc.fit(X, y)\n",
    "\n",
    "        newdf = vectorizer.transform(predict_df_test['dns_seq'])\n",
    "        y_pred = rfc.predict(newdf)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "            all_prec.append(precision_score(test_data['target'], y_pred, average='macro'))\n",
    "            all_rec.append(recall_score(test_data['target'], y_pred, average='macro'))\n",
    "            all_f1.append(f1_score(test_data['target'], y_pred, average='macro'))\n",
    "    print(\"F1-Scores:\", all_f1)\n",
    "    print(\"AVG-Precision:\", \"%0.3f\" % np.mean(all_prec))\n",
    "    print(\"AVG-Recall:\", \"%0.3f\" % np.mean(all_rec))\n",
    "    print(\"AVG-F1:\", \"%0.3f\" % np.mean(all_f1))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3 Open World + Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myseed = 42\n",
    "random.seed(myseed)\n",
    "allf1_resolver = []\n",
    "resolver_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "for i in resolver_indices:\n",
    "    resolver_index = i\n",
    "    number_monitored_sites = 20\n",
    "\n",
    "    cw_data = get_list_of_df(cache=\"CACHE\")[resolver_index]\n",
    "    ow_data = get_list_of_df(world=\"open\", cache=\"CACHE\")[resolver_index]\n",
    "\n",
    "    total_df = cw_data.append(ow_data, ignore_index=True)\n",
    "    app_list = np.unique(cw_data.app_name)\n",
    "    seeds = [42, 24, 2, 4]\n",
    "    print(f\"Resolver - {total_df.name.value_counts().index[0]}\")\n",
    "\n",
    "    all_f1 = []\n",
    "    all_prec = []\n",
    "    all_rec = []\n",
    "    for s in seeds:\n",
    "        training_data, test_data = build_ow_dataframe(total_df, \"multi-class\", s,\n",
    "                                                      app_list, number_monitored_sites, \n",
    "                                                      10, 2/10, 200, 80, 80, 3, 1/3, 4)\n",
    "        predict_df_train = create_dns_sequences(training_data)\n",
    "        predict_df_test = create_dns_sequences(test_data)\n",
    "        # vectorizer and transformer\n",
    "        vectorizer = TfidfVectorizer(tokenizer=lambda x: x.split(\" \"), ngram_range=(1, 3), use_idf=False,\n",
    "                                     sublinear_tf=False, norm='', smooth_idf=False)\n",
    "\n",
    "        X = vectorizer.fit_transform(predict_df_train['dns_seq'])\n",
    "        y = training_data[\"target\"]\n",
    "        rfc = RandomForestClassifier(n_jobs=-1, random_state=myseed)\n",
    "        rfc.fit(X, y)\n",
    "\n",
    "        newdf = vectorizer.transform(predict_df_test['dns_seq'])\n",
    "        y_pred = rfc.predict(newdf)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "            all_prec.append(precision_score(test_data['target'], y_pred, average='macro'))\n",
    "            all_rec.append(recall_score(test_data['target'], y_pred, average='macro'))\n",
    "            all_f1.append(f1_score(test_data['target'], y_pred, average='macro'))\n",
    "    print(\"All F1-Scores\", all_f1)\n",
    "    print(\"AVG-Precision:\", \"%0.3f\" % np.mean(all_prec))\n",
    "    print(\"AVG-Recall:\", \"%0.3f\" % np.mean(all_rec))\n",
    "    print(\"AVG-F1:\", \"%0.3f\" % np.mean(all_f1))\n",
    "    print(\"SD-F1:\", \"%0.3f\" % np.std(all_f1))\n",
    "\n",
    "    allf1_resolver.append(\"%0.3f\" % np.mean(all_f1))\n",
    "    print(\"\\n\")\n",
    "print(\"Total F1 Scores:\", str(allf1_resolver).replace(\"'\", \"\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
